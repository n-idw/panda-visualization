{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the PandaRoot Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python IO for ROOT files\n",
    "import uproot\n",
    "\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# For interactive plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import matplotlib.colors as mcolors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# Seaborn for plotting and styling\n",
    "import seaborn as sns\n",
    "\n",
    "# Pandas for data frame manipulation\n",
    "import pandas as pd\n",
    "\n",
    "from utils.data_processing import (\n",
    "    get_all_mother_ids,\n",
    "    get_process_ids,\n",
    "    is_signal_particle,\n",
    "    get_process_name,\n",
    "    get_particle_tex_name,\n",
    ")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input simulation file:  /home/nikin105/mlProject/data/simulations/XiAntiXi/root/XiAntiXi_sim.root\n"
     ]
    }
   ],
   "source": [
    "simFile = \"/home/nikin105/mlProject/data/simulations/XiAntiXi/root/XiAntiXi_sim.root\"\n",
    "print(\"Input simulation file: \", simFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_tree = uproot.open(\n",
    "    simFile + \":pndsim\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_processes = [\n",
    "    [88888, 3312],  # ppbar -> Xi-\n",
    "    [88888, -3312],  # ppbar -> anti-Xi+\n",
    "    [88888, 3312, -211],  # ppbar -> Xi- -> pi-\n",
    "    [88888, -3312, 211],  # ppbar -> anti-Xi+ -> pi+\n",
    "    [88888, 3312, 3122],  # ppbar -> Xi- -> Lambda0\n",
    "    [88888, -3312, -3122],  # ppbar -> anti-Xi+ -> anti-Lambda0\n",
    "    [88888, 3312, 3122, -211],  # ppbar -> Xi- -> Lambda0 -> pi-\n",
    "    [88888, -3312, -3122, 211],  # ppbar -> anti-Xi+ -> anti-Lambda0 -> pi+\n",
    "    [88888, 3312, 3122, 2212],  # ppbar -> Xi- -> Lambda0 -> p\n",
    "    [88888, -3312, -3122, -2212],  # ppbar -> anti-Xi+ -> anti-Lambda0 -> anti-p\n",
    "]\n",
    "\n",
    "# signal_processes = [[13], [-13]]  # muon, anti-muon\n",
    "\n",
    "\n",
    "# signal_process_ids = [\n",
    "#     [0, 0],\n",
    "#     [0, 0, 4],\n",
    "#     [0, 0, 4, 4],\n",
    "# ]\n",
    "\n",
    "signal_process_ids = [\n",
    "    [0, 0],\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 0, 0],\n",
    "]\n",
    "\n",
    "# signal_process_ids = [[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "momentum_keys = [\n",
    "    \"MCTrack.fPx\",\n",
    "    \"MCTrack.fPy\",\n",
    "    \"MCTrack.fPz\",\n",
    "]\n",
    "\n",
    "pid_keys = [\n",
    "    \"MCTrack.fMotherID\",\n",
    "    \"MCTrack.fSecondMotherID\",\n",
    "    \"MCTrack.fProcess\",\n",
    "    \"MCTrack.fPdgCode\",\n",
    "]\n",
    "stt_keys = [\"STTPoint.fTrackID\"]\n",
    "\n",
    "momenta = sim_tree.arrays(\n",
    "    expressions=momentum_keys + pid_keys + stt_keys, library=\"pd\"\n",
    ")\n",
    "\n",
    "my_dtypes = {\n",
    "    \"MCTrack.fPx\": \"float32\",\n",
    "    \"MCTrack.fPy\": \"float32\",\n",
    "    \"MCTrack.fPz\": \"float32\",\n",
    "    \"MCTrack.fPdgCode\": \"int32\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_row(row) -> pd.Series:\n",
    "    output_dict = {}\n",
    "    unique_track_ids = np.unique(np.array(row[\"STTPoint.fTrackID\"], dtype=int))\n",
    "    for key in momentum_keys + [\"MCTrack.fPdgCode\"]:\n",
    "        output_dict[key] = np.array(row[key][unique_track_ids], dtype=my_dtypes[key])\n",
    "\n",
    "    mother_ids = get_all_mother_ids(\n",
    "        mother_ids=row[\"MCTrack.fMotherID\"],\n",
    "        second_mother_ids=row[\"MCTrack.fSecondMotherID\"],\n",
    "    )\n",
    "\n",
    "    output_dict[\"is_signal\"] = np.zeros(len(unique_track_ids), dtype=bool)\n",
    "    output_dict[\"particle_name\"] = []\n",
    "    output_dict[\"production_process\"] = []\n",
    "\n",
    "    particle_num = 0\n",
    "    for particle_id in unique_track_ids:\n",
    "        mc_ids, process_codes = get_process_ids(\n",
    "            process_ids=np.array(row[\"MCTrack.fProcess\"], dtype=int),\n",
    "            mother_ids=mother_ids,\n",
    "            pdg_ids=np.array(row[\"MCTrack.fPdgCode\"], dtype=int),\n",
    "            particle_id=particle_id,\n",
    "        )\n",
    "        output_dict[\"is_signal\"][particle_num] = is_signal_particle(\n",
    "            process_mc_ids=mc_ids,\n",
    "            process_ids=process_codes,\n",
    "            signal_mc_ids=signal_processes,\n",
    "            signal_process_ids=signal_process_ids,\n",
    "        )\n",
    "        output_dict[\"production_process\"].append(\n",
    "            get_process_name(process_id=process_codes[-1])\n",
    "        )\n",
    "        output_dict[\"particle_name\"].append(\n",
    "            \"$\"\n",
    "            + get_particle_tex_name(pdg_id=np.array(row[\"MCTrack.fPdgCode\"][particle_id], dtype=int))\n",
    "            + \"$\"\n",
    "        )\n",
    "\n",
    "        output_dict[\"pt\"] = np.sqrt(\n",
    "            output_dict[\"MCTrack.fPx\"] ** 2 + output_dict[\"MCTrack.fPy\"] ** 2\n",
    "        )\n",
    "        output_dict[\"P\"] = np.sqrt(\n",
    "            output_dict[\"MCTrack.fPx\"] ** 2\n",
    "            + output_dict[\"MCTrack.fPy\"] ** 2\n",
    "            + output_dict[\"MCTrack.fPz\"] ** 2\n",
    "        )\n",
    "        output_dict[\"theta\"] = np.arctan2(output_dict[\"pt\"], output_dict[\"MCTrack.fPz\"])\n",
    "        output_dict[\"phi\"] = np.arctan2(\n",
    "            output_dict[\"MCTrack.fPy\"], output_dict[\"MCTrack.fPx\"]\n",
    "        )\n",
    "        output_dict[\"eta\"] = -np.log(np.tan(output_dict[\"theta\"] / 2))\n",
    "\n",
    "        particle_num += 1\n",
    "\n",
    "    return pd.Series(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe_in_parallel(df):\n",
    "    # Initialize the number of processes based on CPU core count\n",
    "    num_workers = 10\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Using list() to ensure all futures are executed and to get the results\n",
    "        results = list(tqdm(executor.map(compute_row, [row for _, row in df.iterrows()]), total=len(df)))\n",
    "\n",
    "    # Combine results back into a single DataFrame\n",
    "    processed_df = pd.DataFrame(results)\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_dataframe_in_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmomenta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m new_df \u001b[38;5;241m=\u001b[39m new_df\u001b[38;5;241m.\u001b[39mexplode(\n\u001b[1;32m      4\u001b[0m     momentum_keys\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_signal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduction_process\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticle_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMCTrack.fPdgCode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m new_df\u001b[38;5;241m.\u001b[39mto_parquet(\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/nikin105/mlProject/data/simulations/XiAntiXi/processed/particle_data.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m )\n",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m, in \u001b[0;36mprocess_dataframe_in_parallel\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m num_workers \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mcpu_count() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mnum_workers) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Using list() to ensure all futures are executed and to get the results\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tqdm(\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df)))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Combine results back into a single DataFrame\u001b[39;00m\n\u001b[1;32m     10\u001b[0m processed_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/vis/lib/python3.10/concurrent/futures/process.py:766\u001b[0m, in \u001b[0;36mProcessPoolExecutor.map\u001b[0;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunksize must be >= 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 766\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_process_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m_get_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chain_from_iterable_of_lists(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/vis/lib/python3.10/concurrent/futures/_base.py:610\u001b[0m, in \u001b[0;36mExecutor.map\u001b[0;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 610\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(fn, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[0;32m~/miniconda3/envs/vis/lib/python3.10/concurrent/futures/_base.py:610\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    608\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 610\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[0;32m~/miniconda3/envs/vis/lib/python3.10/concurrent/futures/process.py:734\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# Wake up queue management thread\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor_manager_thread_wakeup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwakeup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_to_dynamically_spawn_children:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adjust_process_count()\n",
      "File \u001b[0;32m~/miniconda3/envs/vis/lib/python3.10/concurrent/futures/process.py:79\u001b[0m, in \u001b[0;36m_ThreadWakeup.wakeup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vis/lib/python3.10/multiprocessing/connection.py:200\u001b[0m, in \u001b[0;36m_ConnectionBase.send_bytes\u001b[0;34m(self, buf, offset, size)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m offset \u001b[38;5;241m+\u001b[39m size \u001b[38;5;241m>\u001b[39m n:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuffer length < offset + size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m:\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vis/lib/python3.10/multiprocessing/connection.py:411\u001b[0m, in \u001b[0;36mConnection._send_bytes\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send(buf)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;66;03m# Issue #20540: concatenate before sending, to avoid delays due\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;66;03m# to Nagle's algorithm on a TCP socket.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# Also note we want to avoid sending a 0-length buffer separately,\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;66;03m# to avoid \"broken pipe\" errors if the other end closed the pipe.\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vis/lib/python3.10/multiprocessing/connection.py:368\u001b[0m, in \u001b[0;36mConnection._send\u001b[0;34m(self, buf, write)\u001b[0m\n\u001b[1;32m    366\u001b[0m remaining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(buf)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     remaining \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_df = process_dataframe_in_parallel(momenta)\n",
    "\n",
    "new_df = new_df.explode(\n",
    "    momentum_keys\n",
    "    + [\"is_signal\", \"production_process\", \"particle_name\", \"MCTrack.fPdgCode\"] + [\"pt\", \"P\", \"theta\", \"phi\", \"eta\"],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "new_df.to_parquet(\n",
    "    \"/home/nikin105/mlProject/data/simulations/XiAntiXi/processed/particle_data.parquet\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_ids = sim_tree[\"STTPoint.fTrackID\"].array(library=\"pd\")\n",
    "unique_track_ids = []\n",
    "for entry in track_ids:\n",
    "    unique_track_ids.append(np.unique(entry))\n",
    "\n",
    "momentum_keys = [\n",
    "    \"MCTrack.fPx\",\n",
    "    \"MCTrack.fPy\",\n",
    "    \"MCTrack.fPz\",\n",
    "]\n",
    "\n",
    "pid_keys = [\n",
    "    \"MCTrack.fMotherID\",\n",
    "    \"MCTrack.fSecondMotherID\",\n",
    "    \"MCTrack.fProcess\",\n",
    "    \"MCTrack.fPdgCode\",\n",
    "]\n",
    "stt_keys = [\"STTPoint.fTrackID\"]\n",
    "\n",
    "momenta = sim_tree.arrays(\n",
    "    expressions=momentum_keys + pid_keys + stt_keys, library=\"pd\", entry_stop=100\n",
    ")\n",
    "\n",
    "\n",
    "for key in momentum_keys:\n",
    "    momenta[key] = momenta.apply(\n",
    "        lambda row: [row[key][idx] for idx in unique_track_ids[row.name]],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "momenta[\"mother_ids\"] = momenta.apply(\n",
    "    lambda row: get_all_mother_ids(\n",
    "        mother_ids=row[\"MCTrack.fMotherID\"],\n",
    "        second_mother_ids=row[\"MCTrack.fSecondMotherID\"],\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "momenta = momenta.drop(columns=[\"MCTrack.fMotherID\", \"MCTrack.fSecondMotherID\"])\n",
    "\n",
    "momenta[\"process_ids\"] = momenta.apply(\n",
    "    lambda row: [\n",
    "        get_process_ids(\n",
    "            process_ids=row[\"MCTrack.fProcess\"],\n",
    "            mother_ids=row[\"mother_ids\"],\n",
    "            pdg_ids=row[\"MCTrack.fPdgCode\"],\n",
    "            particle_id=particle_id,\n",
    "        )\n",
    "        for particle_id in unique_track_ids[row.name]\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "momenta = momenta.drop(columns=[\"MCTrack.fProcess\", \"MCTrack.fPdgCode\", \"mother_ids\"])\n",
    "\n",
    "momenta[\"is_signal\"] = momenta.apply(\n",
    "    lambda row: [\n",
    "        is_signal_particle(\n",
    "            process_mc_ids=row[\"process_ids\"][particle_id][0],\n",
    "            process_ids=row[\"process_ids\"][particle_id][1],\n",
    "            signal_mc_ids=signal_processes,\n",
    "            signal_process_ids=signal_process_ids,\n",
    "        )\n",
    "        for particle_id in range(len(row[\"process_ids\"]))\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "momenta[\"production_process\"] = momenta.apply(\n",
    "    lambda row: [\n",
    "        get_process_name(process_id=row[\"process_ids\"][particle_id][1][-1])\n",
    "        for particle_id in range(len(row[\"process_ids\"]))\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "momenta[\"pdg_code\"] = momenta.apply(\n",
    "    lambda row: [\n",
    "        row[\"process_ids\"][particle_id][0][-1]\n",
    "        for particle_id in range(len(row[\"process_ids\"]))\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "momenta[\"particle_name\"] = momenta.apply(\n",
    "    lambda row: [\n",
    "        r\"$\" + get_particle_tex_name(row[\"process_ids\"][particle_id][0][-1]) + r\"$\"\n",
    "        for particle_id in range(len(row[\"process_ids\"]))\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "momenta = momenta.drop(columns=[\"process_ids\"])\n",
    "\n",
    "momenta = momenta.explode(\n",
    "    momentum_keys + [\"is_signal\", \"production_process\", \"particle_name\", \"pdg_code\"],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "momenta[\"pt\"] = momenta.apply(\n",
    "    lambda row: np.sqrt(row[\"MCTrack.fPx\"] ** 2 + row[\"MCTrack.fPy\"] ** 2), axis=1\n",
    ")\n",
    "momenta[\"P\"] = momenta.apply(\n",
    "    lambda row: np.sqrt(\n",
    "        row[\"MCTrack.fPx\"] ** 2 + row[\"MCTrack.fPy\"] ** 2 + row[\"MCTrack.fPz\"] ** 2\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "momenta[\"theta\"] = momenta.apply(\n",
    "    lambda row: np.arctan2(row[\"pt\"], row[\"MCTrack.fPz\"]), axis=1\n",
    ")\n",
    "momenta[\"phi\"] = momenta.apply(\n",
    "    lambda row: np.arctan2(row[\"MCTrack.fPy\"], row[\"MCTrack.fPx\"]), axis=1\n",
    ")\n",
    "momenta[\"eta\"] = momenta.apply(lambda row: -np.log(np.tan(row[\"theta\"] / 2)), axis=1)\n",
    "\n",
    "momenta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momenta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "momenta.to_parquet(\n",
    "    \"/home/nikin105/mlProject/data/simulations/XiAntiXi/processed/particle_data.parquet\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momenta = pd.read_parquet(\n",
    "    \"/home/nikin105/mlProject/data/simulations/XiAntiXi/processed/particle_data.parquet\"\n",
    ")\n",
    "momenta.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
